Language Parsing: The Lexer
6/22/2011

The first problem/question I encountered when I started to explore how to make a language is 
"How does a text file get converted into executable code in a brand new language?".

It turns out lots of really smart people have recognized the recurring need for new languages and have built tools whose sole purpose is to compile compilers. The most enduring called Yacc, an acronym for "Yet another compiler compiler". It has a companion tool for lexical analysis called Lex. Their latest incarnations are Bison and Flex. It is the job of the lexical analysis tool to look at an input stream and identify tokens. The job of the larger parser, Bison or Yacc, is to assemble programmatic meaning out for the stream of tokens. While the two programs are significantly different, their usage is typically bound. The Bison files define the grammar, and the Flex files identify tokens, but only as a pair to they deconstruct a language. 

As a first experiment, I wanted to try to build something with the lexer alone. The remainder of this post will be about two experiments with Flex. In the first experiment, the application uses Flex to repeat slightly modified the any input that matches basic calculator functionality. This is an easy way to assure that the token pattern matching is correct. In the second experiment, I build a C++ class for the doing really basic calculations on a queue of tokens. It goes from left to right only, and dies in any situation where the input doesn't follow expectations. These limitation highlight the necessity for Bison, and I will get into combining the two application in the next section.

Flex is mostly written in C, but has a bit of domain specific language, DSL, binding it together. Files have to follow a certain format:

<script src="https://gist.github.com/1042801.js"> </script>

The above gist file won't actually run, since we don't have a my_file.c for the lexer to include. Checkout the project to get some source code that will actually run. 

